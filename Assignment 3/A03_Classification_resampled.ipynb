{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEDZpgOXLL92"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from collections import Counter\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W04j4VrTOdkc"
      },
      "outputs": [],
      "source": [
        "#Importing dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/meetgojiya98/Business_Analytics_MBA6636/main/Assignment%202/bank-full.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzRLIcsaVfcY"
      },
      "outputs": [],
      "source": [
        "# converting object types variables to ordinal type \n",
        "for v in df.columns:\n",
        "  if df[v].dtype == 'object':\n",
        "    df[v] = pd.Categorical(df[v])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlsaxuHwW5zW"
      },
      "outputs": [],
      "source": [
        "# encoding categorical variables with numerical values\n",
        "encoded_categories = {\n",
        "                \"job\": {\"unknown\": -1, \"blue-collar\": 1, \"management\":2 , \"technician\": 3, \"admin.\": 4,\"services\": 5, \n",
        "                         \"retired\": 6, \"self-employed\": 7, \"entrepreneur\": 8, \"unemployed\": 9, \"housemaid\": 10,\n",
        "                         \"student\": 11},\n",
        "                \"marital\": {\"single\": 1, \"married\": 2 ,\"divorced\": 3},\n",
        "                \"education\": {\"unknown\":-1, \"primary\": 1, \"secondary\": 2 ,\"tertiary\": 3},\n",
        "                \"default\": {\"no\": 0, \"yes\": 1},\n",
        "                \"housing\": {\"no\": 0, \"yes\": 1},\n",
        "                \"loan\": {\"no\": 0, \"yes\": 1},\n",
        "                \"contact\": {\"unknown\": -1 , \"cellular\": 1, \"telephone\": 2},\n",
        "                \"month\": {\"jan\": 1, \"feb\":2 , \"mar\": 3, \"apr\": 4,\"may\": 5, \"jun\": 6, \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12},\n",
        "                \"poutcome\": {\"unknown\": -1, \"failure\": 0, \"success\": 1, \"other\": 2},\n",
        "                \"y\": {\"no\": 0, \"yes\": 1} \n",
        "                    }\n",
        "df = df.replace(encoded_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHJIEVyz7bph"
      },
      "outputs": [],
      "source": [
        "# dimensionality reduction\n",
        "df = df.drop(['contact'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8f2DusbpRf-"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv37vsPK7ojh"
      },
      "source": [
        "Dropping the 'contact' variable because it's not relevant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcN3Rdyq72IZ"
      },
      "outputs": [],
      "source": [
        "# replacing 'unknown' in the poutcome variable in order to generate meaningful insights\n",
        "df.loc[df['poutcome']==-1, 'poutcome'] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4kDis0a8wgh"
      },
      "outputs": [],
      "source": [
        "# generating dummy variables for the 'job', 'marital', and 'poutcome' variables using one-hot encoding\n",
        "one_hot_dummy = ['job', 'marital', 'poutcome']\n",
        "df = pd.get_dummies(df, columns=one_hot_dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uydu0Juq9eg-"
      },
      "outputs": [],
      "source": [
        "# checking columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f51b36dSiXt3"
      },
      "source": [
        "# Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ele9_hE296ps"
      },
      "outputs": [],
      "source": [
        "# splitting the data into training and test data sets (80:20)\n",
        "l = df.drop('y', axis=1)\n",
        "m = df[['y']]\n",
        "x_train, l_test, m_train, m_test = train_test_split(l, m, test_size=0.30, random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhGLknho-8Hr"
      },
      "outputs": [],
      "source": [
        "# scaling data\n",
        "scaled_l_train = preprocessing.scale(x_train)\n",
        "scaled_l_test = preprocessing.scale(l_test)\n",
        "l_train = scaled_l_train\n",
        "l_test = scaled_l_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viDjRgcTFezb"
      },
      "outputs": [],
      "source": [
        "# cross validation\n",
        "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mhmAk47_d3j"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "log_reg = LogisticRegression(solver = 'lbfgs')\n",
        "log_reg.fit(l_train, m_train.values.ravel())\n",
        "\n",
        "# Test data set predictions\n",
        "log_reg_m_predict = log_reg.predict(l_test)\n",
        "log_reg_score = log_reg.score(l_test, m_test)\n",
        "\n",
        "log_reg_score_acc = accuracy_score(m_test, log_reg_m_predict)\n",
        "log_reg_precison = precision_score(m_test, log_reg_m_predict)\n",
        "log_reg_recall = recall_score(m_test, log_reg_m_predict)\n",
        "log_reg_f1 = f1_score(m_test, log_reg_m_predict)\n",
        "\n",
        "cross_validation_result = model_selection.cross_val_score(log_reg, l_train, m_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "print('\\nLogistic Regression classification Report : \\n',metrics.classification_report(m_test, log_reg_m_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c6TMaUAj45B"
      },
      "source": [
        "The prediction has a accuracy score of 90%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKkhftPl_9Oi"
      },
      "outputs": [],
      "source": [
        "# creating and visualizing confusion matrix\n",
        "cm = metrics.confusion_matrix(m_test, log_reg_m_predict)\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(log_reg_score_acc)\n",
        "plt.title(all_sample_title, size = 15);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7H4SYE_b8tl"
      },
      "source": [
        "Here, \n",
        "\n",
        "* True positive is 11748\n",
        "* True negative is 490\n",
        "* False positive is 282 (Type I error)\n",
        "* False negative is 1044 (Type II error)\n",
        "\n",
        "The prediction had a total of 12,238 accurate results and 1,326 non-accurate results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJZprya4ok18"
      },
      "outputs": [],
      "source": [
        "# splitting the data into training and test data sets (50:50)\n",
        "l = df.drop('y', axis=1)\n",
        "m = df[['y']]\n",
        "x_train, l_test, m_train, m_test = train_test_split(l, m, test_size=0.50, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIHoEQaFo9eU"
      },
      "outputs": [],
      "source": [
        "# scaling data\n",
        "scaled_l_train = preprocessing.scale(x_train)\n",
        "scaled_l_test = preprocessing.scale(l_test)\n",
        "l_train = scaled_l_train\n",
        "l_test = scaled_l_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_XVIQ0lo9r2"
      },
      "outputs": [],
      "source": [
        "# cross validation\n",
        "kfold = model_selection.KFold(n_splits=50, shuffle=True, random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-urAvPUapKjN"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "log_reg = LogisticRegression(solver = 'lbfgs')\n",
        "log_reg.fit(l_train, m_train.values.ravel())\n",
        "\n",
        "# Test data set predictions\n",
        "log_reg_m_predict = log_reg.predict(l_test)\n",
        "log_reg_score = log_reg.score(l_test, m_test)\n",
        "\n",
        "log_reg_score_acc = accuracy_score(m_test, log_reg_m_predict)\n",
        "log_reg_precison = precision_score(m_test, log_reg_m_predict)\n",
        "log_reg_recall = recall_score(m_test, log_reg_m_predict)\n",
        "log_reg_f1 = f1_score(m_test, log_reg_m_predict)\n",
        "\n",
        "cross_validation_result = model_selection.cross_val_score(log_reg, l_train, m_train.values.ravel(), cv=kfold, scoring='accuracy')\n",
        "print('\\nLogistic Regression classification Report : \\n',metrics.classification_report(m_test, log_reg_m_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnDsaUgUpVBS"
      },
      "outputs": [],
      "source": [
        "# creating and visualizing confusion matrix\n",
        "cm = metrics.confusion_matrix(m_test, log_reg_m_predict)\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(log_reg_score_acc)\n",
        "plt.title(all_sample_title, size = 15);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYP1qeErqkQq"
      },
      "source": [
        "Here, \n",
        "\n",
        "* True positive is 19518\n",
        "* True negative is 821\n",
        "* False positive is 441 (Type I error)\n",
        "* False negative is 1826 (Type II error)\n",
        "\n",
        "The prediction had a total of 20,339 accurate results and ,267 non-accurate results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oDX__8_ttHc8",
        "outputId": "49026ac8-eec4-49e7-b6a5-fe728c9b1ea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folds: 392, MSE: 0.11201637701557385, STD: 0.14086879829706359\n"
          ]
        }
      ],
      "source": [
        "# Leave-One-Out Cross-Validation (LOOCV)\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "X = df.drop('y', axis=1)\n",
        "y = df[['y']]\n",
        "loo.get_n_splits(X)\n",
        "\n",
        "crossvalidation = KFold(n_splits=392, random_state=None, shuffle=False)\n",
        "\n",
        "scores = cross_val_score(log_reg, X, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation, n_jobs=1)\n",
        "\n",
        "print(\"Folds: \" + str(len(scores)) + \", MSE: \" + str(np.mean(np.abs(scores))) + \", STD: \" + str(np.std(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMz3LTt-nTQ8"
      },
      "source": [
        "# Bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "URTVWb-F63xq",
        "outputId": "3b71af97-0b1a-4c9e-e4d7-b00f09cdb9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped Mean Length = 40.93494331025635, 95% CI = [40.83195019 41.03547588]\n"
          ]
        }
      ],
      "source": [
        "# Draw some random sample with replacement and append mean to mean_lengths.\n",
        "mean_lengths, sims = [], 1000\n",
        "for i in range(sims):\n",
        "    temp_sample = np.random.choice(df[\"age\"], replace=True, size=len(df[\"age\"]))\n",
        "    sample_mean = np.mean(temp_sample)\n",
        "    mean_lengths.append(sample_mean)\n",
        "    \n",
        "# Calculate bootstrapped mean and 95% confidence interval.\n",
        "boot_mean = np.mean(mean_lengths)\n",
        "boot_95_ci = np.percentile(mean_lengths, [2.5, 97.5])\n",
        "print(\"Bootstrapped Mean Length = {}, 95% CI = {}\".format(boot_mean, boot_95_ci))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pGqr1c-DzsRQ"
      },
      "outputs": [],
      "source": [
        "# Bootstrapping Logistic Regression model\n",
        "rsquared_boot, coefs_boot, sims = [], [], 1000\n",
        "reg_fit = sm.Logit(df['y'], df.iloc[:,1:]).fit()\n",
        "\n",
        "# Run 1K iterations\n",
        "for i in range(sims):\n",
        "    # First create a bootstrap sample with replacement with n=df.shape[0]\n",
        "    bootstrap = df.sample(n=df.shape[0], replace=True)\n",
        "    # Fit the regression and append the r square to rsquared_boot\n",
        "    rsquared_boot.append(sm.OLS(bootstrap['y'],bootstrap.iloc[:,1:]).fit().rsquared)\n",
        "\n",
        "# # Calculate 95% CI on rsquared_boot\n",
        "r_sq_95_ci = np.percentile(rsquared_boot, [2.5, 97.5])\n",
        "print(\"R Squared 95% CI = {}\".format(r_sq_95_ci))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "A03_Classification_resampled.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}